= Google Cloud Auctionmark Benchmark

Contained within this folder are a number of things for setting up & running a cluster of containerized auctionmark running worker tasks on Google Cloud Platform.

Within this README is the following:

* Instructions for setting up the docker image.
* How to setup the infra necessary on Google Cloud
* How to push the docker image to Google Cloud.

== Requirements

For local development, you will need the following:
* To run the various scripts and commands within this folder, you will need the `gcloud` command line tool:
** See https://cloud.google.com/sdk[**here**] for more details. 
* Ensure that you are https://cloud.google.com/sdk/gcloud/reference/auth/login[authenticated with the CLI] and have sufficient permissions to do all of the below.
* `docker` available on your machine.
* `kubectl` available on your machine.

In order to deploy the necessary infrastructure on Google Cloud, you will need the following:

* An existing Google Cloud project with the following activated APIs:
** Cloud Deployment Manager API
** Cloud Storage API
** Pub/Sub API
** IAM API
** Compute Engine API
** Kubernetes Engine API
* Within the configuration, we create a custom IAM role for all of the necessary infrastructure and assign it to a service account. In order for Cloud Deployment Manager to create this, it will require IAM permissions to do so:
** See link:https://cloud.google.com/iam/docs/maintain-custom-roles-deployment-manager#grant_permissions["Grant permissions to the Google APIs service account"] on how to do this.
** We need to grant the following roles to the Google APIs service account:
*** `roles/iam.roleAdmin`
*** `roles/iam.serviceAccountAdmin`

== Creating the ShadowJAR

Included within this folder is a script, `scripts/build-google-cloud-bench.sh`, which does the following:

* Creates a Shadow JAR of the `cloud-benchmark:google-cloud` project.
** This contains the compiled `cloud-benchmark` project, which has a main file that runs auctionmark & configures it with provided node config, and also any of the dependencies we require to run the Google Cloud module
* Creates a docker image, copying in the Shadow JAR and the `google-cloud-config.yaml` file with the node config.
** If you want to set any JVM opts - do it by editing the Dockerfile's `ENTRYPOINT`.


It will build the local image as `xtdb-google-cloud-bench:latest`.

== Pushing the Docker Image to Google Cloud

Firstly, we wil need to set up a google cloud artifact repository to store the docker image. This can be done by running the following command:

```bash
gcloud artifacts repositories create xtdb-google-cloud-bench-repo --repository-format=docker --location=europe-west1 --description="Repository for storing the xtdb-google-cloud-bench docker image"
```

You can view that the repository was created used the following command:
```bash
gcloud artifacts repositories list
```

We can configure our docker client  repository by running the following command:
```bash
gcloud auth configure-docker europe-west1-docker.pkg.dev
```

We now tag the image we created in the previous step to match our created repository:
```bash
docker tag xtdb-google-cloud-bench:latest europe-west1-docker.pkg.dev/xtdb-scratch/xtdb-google-cloud-bench-repo/xtdb-google-cloud-bench:latest
```

Finally, we can push the image to the Google Cloud Artifact Repository:
```bash
docker push europe-west1-docker.pkg.dev/xtdb-scratch/xtdb-google-cloud-bench-repo/xtdb-google-cloud-bench:latest
```

== Setting up the infra on Google Cloud

Within this directory is a subdirectory, `deployment-manager`, that contains the Google Cloud Deployment Manager configuration for setting up all the necessary infra on Google Cloud. We also provide a script to create the deployment, `create-google-cloud-deployment.sh`.

You can edit the configuration for the deployment under the `xtdb-google-cloud-bench.yaml` file.

To create the initial deployment, run the following command:
```
./scripts/create-google-cloud-deployment.sh
```

This will set up the following:

* A Cloud Storage bucket
* A Pub/Sub topic, subscribed to notifications from the Cloud Storage bucket.
* A custom role for all of the necessary permissions for XTDB to use the above:
** Using the bucket (get, create, delete, list, and update storage objects)
** Creating, consuming, and deleting subscriptions on PubSub topics.
* A service account with the custom role attached.
* A Kubernetes cluster with a single node pool.

If you make any changes to the deployment configuration, you can update the deployment by running the following command:
```
./scripts/update-google-cloud-deployment.sh
```

With the infrastructure set up and created, we should ensure that the created service account has the permissions needed to pull the docker image from the Google Cloud Artifact Repository, and to interract with the other resources. Run the two following commands (ensuring members/roles match what is expected/created):
```
gcloud artifacts repositories add-iam-policy-binding xtdb-google-cloud-bench-repo \
   --location=europe-west1 \
   --member=serviceAccount:xtdb-bench-sa-task@xtdb-scratch.iam.gserviceaccount.com \
   --role=roles/artifactregistry.reader

gcloud projects add-iam-policy-binding projects/xtdb-scratch \
  --member serviceAccount:xtdb-bench-sa-task@xtdb-scratch.iam.gserviceaccount.com \
  --role=projects/xtdb-scratch/roles/xtdb_auctionmark_bench_role
```

With the cluster up and running, you can now deploy the benchmark containers to it.

== Deploying the Benchmark Containers

Before trying to deploy the benchmark containers, you will need to ensure that you have the necessary permissions to deploy to the Kubernetes cluster. You can do this by running the following command:
```
gcloud container clusters get-credentials google-cloud-auctionmark-benchmark --zone europe-west1-b
```

NOTE: You may need to update the auth plugin within google cloud - see here https://cloud.google.com/blog/products/containers-kubernetes/kubectl-auth-changes-in-gke and also ensure your various gcloud components are up to date.

This will configure your `kubectl` to use the credentials for the Kubernetes cluster. 

Prior to setting up the kubernetes deployment, we will need to set up one final thing for it to use - a Kubernetes Service Account. This service account will be used by the pods to authenticate with Google Cloud applications, using the custom role we created earlier. To create the service account, run the following command:
```
kubectl create serviceaccount xtdb-k8s-service-account --namespace default 
```

We need to link our kubernetes service account to our created IAM Service Account with the relevant permissions, so that the pods can authenticate with Google Cloud. Following the instructions from https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity#kubernetes-sa-to-iamidentity, we run the following two commands:
```bash
gcloud iam service-accounts add-iam-policy-binding xtdb-bench-sa-task@xtdb-scratch.iam.gserviceaccount.com \
    --role roles/iam.workloadIdentityUser \
    --member "serviceAccount:xtdb-scratch.svc.id.goog[default/xtdb-k8s-service-account]"

kubectl annotate serviceaccount xtdb-k8s-service-account \
    --namespace default \
    iam.gke.io/gcp-service-account=xtdb-bench-sa-task@xtdb-scratch.iam.gserviceaccount.com
```

The config for the deployments/jobs live under `kubernetes` - within these, you can set/configure any of the necessary parameters for running the image on the cluster. When ready to run a single node auctionmark job, run the following command:
```
kubectl apply -f kubernetes/single-node-auctionmark.yaml
```

You can see the status of pod creation using the following:
```
kubectl get pods
```

With the pod name of the job in hand & when it is created, you can locally trail the logs by doing the following:
```
kubectl logs xtdb-single-node-auctionmark-<pod suffix> -f
```

NOTE: If you follow the below and clear up/delete the persistent storage volumes, you will drop the TxLog and Local Disk Cache data between runs. This may or may not be desired - to note, recreating persistent storage volumes can take some time.

== Clear up between runs

If you want to totally clear up data between runs, you'll want to do the following:

* Clear up the job/pods
* Empty the Cloud Storage bucket
* Delete the Persistent Storage volume containing the TxLog
* Delete the Persistent Storage volume containing the Local Disk Caches

.Clear up the Workload

To clear up the workload, you can do so in Google Cloud or using kubectl. To do so using kubectl, you can do the following:
```bash
kubectl delete jobs xtdb-single-node-auctionmark
```

.Command to empty the Cloud Storage bucket:
```bash
gcloud storage rm gs://xtdb-am-bench-object-store/**
```

.Deleting Persistent Storage Volumes:
You can remove the Persistent Storage volumes within the google cloud UI, but will need to be careful to ensure they are both removed from GKE and deleted within Compute Engine's storage as well. You will need to ensure any pods are closed/deleted first, and then to delete them, you can do the following:
```bash
kubectl delete pvc xtdb-pvc-log
kubectl delete pvc xtdb-pvc-local-caches
``` 

NOTE: You do not necessarily _need_ to delete all of the above between runs - you can also change the kubernetes config map to use slightly different directory names (ie, changing bucket prefix, new local-disk-cache directory, etc) to avoid conflicts between runs. 

.Helper Script

For convenience, there is a script, `clear-google-cloud-bench.sh`, that will clear up any existing/lingering jobs, empty the Cloud Storage bucket, and delete the Persistent Storage volumes.
```bash
./scripts/clear-google-cloud-bench.sh
```
